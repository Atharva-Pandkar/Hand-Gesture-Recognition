# PRCV_Final_Project

Group mnembers:
Kristine N Umeh
Atharva Pandkar
Dharsan Krishnamoorthy 

Project description:
There are several ways to implement sign recognition, and three distinct methods have been explored. The first approach involves recognizing sign language gestures for individual letters in the English language, using the ASL Dataset. This dataset contains around 1000 static images that cover all letters except J and Z. The second implementation involves using hand gestures to control devices, as tested on the HAGRID Dataset. This dataset contains over 550,000 FullHD RGB images divided into 18 classes, with data from 34,730 individuals between the ages of 18 and 65. The ResNet 18 model was used for this task. Finally, the Google GISLR Dataset was used to classify words based on sign language used in videos. This dataset contains 250-word classifications and is stored in frames featuring various signs. Overall, these three implementations demonstrate the versatility of sign recognition and its potential applications in various fields and we predict that they could be be combined to produce a more robust and efficient sign and gesturre recognition model.


Kaggle: https://www.kaggle.com/code/atharvapandkar18/test1

URL for presentation: 
https://drive.google.com/drive/folders/131gjcHS8m5ERJAm5Y2iCrFQ6VpwdMl7o
